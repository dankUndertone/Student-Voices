{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=darkblue>Reviewing LDA Results for Ratings 35-60</font>\n",
    "\n",
    "In this notebook we review the topics that resulted from the LDA experiments on the corpus of reviews that received ratings between 35 & 60. We will present the results of each run from highest average coherence to lowest. The topics, originally numbered 0-K have been given descriptive topics which were composed based on the key words and sample reviews with the highest relevance. \n",
    "\n",
    "\n",
    "### TO-DO \n",
    "\n",
    "* When displaying sample sentences, display the percentage distribution results to see how much they're predictive of other categories. \n",
    "\n",
    "\n",
    "\n",
    "## <font color=darkblue>Content</font>\n",
    "\n",
    "**General Conclusions - Themes** </font>\n",
    "<br>Themes are presented first. A table with the labels and topic distributions is shown followed by a general description of the topics that are were consistently found to be discussed in the corpus and their relative frequencies. \n",
    "\n",
    "\n",
    "**Trial Breakdowns** </font>\n",
    "<br>The results make up the majority of this notebook. They describe the outcomes of each LDA trial (4 total). They are organized by most coherent to least coherent. The content of each breakdown are: \n",
    "\n",
    ">*1. the parameters for that trial (reivew length, cleaning setup and optimal number of topics based on coherence).*\n",
    "\n",
    ">*2. a bar graph showing the distribution of dominant topics across reviews with a line-graph overlayed showing the coherence of each topic. *\n",
    "\n",
    ">*3. pyLDAvis bubble graph showing the distribution the topics in the language model vector space where the size of the bubble represent the relative distribution of each topic and key words for the topic are presented on the right side of the graph.*\n",
    "\n",
    ">*4. topic breakdowns of each topic in the trial which include: *\n",
    ">  - *the topic description & some choice reivews to represent the topic*\n",
    ">  - *a graph of how the reviews that have this topic as the most dominant topic contribute to the definition of the topic*\n",
    ">  - *the topic key words (words most predictive of belonging to the topic)*\n",
    ">  - *a larger sample of reviews*\n",
    "\n",
    "<font color=green>**Funny Reviews** </font>\n",
    "<br>Along side the choice reviews, we sometimes highlight funny reviews that stood out. Search \"Funny Reviews\" to see the ones we picked out. Enjoy :) \n",
    "\n",
    "<font color=green>**WTF Reviews** </font>\n",
    "<br>We also highlighted totally outrageous reviews that caught our attention. This is certainly not an exhaustive list, future analyses of this corpus (and the other ratings) will examine language more closely and highlight outliers as they come up. \n",
    "\n",
    "\n",
    "**Appendix**\n",
    "<br>At the end of this notebook are some extra blocks that generate the content needed for this notebook. \n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n"
     ]
    }
   ],
   "source": [
    "import bear_necessities as bn \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as snss\n",
    "import random\n",
    "import visuals \n",
    "import modeling_tools as mt\n",
    "from importlib import reload\n",
    "visuals = reload(visuals)\n",
    "from visuals import get_topic_reviews\n",
    "from visuals import plot_dominant_topics\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus_length</th>\n",
       "      <th>data_configuration</th>\n",
       "      <th>duration</th>\n",
       "      <th>filtered_length</th>\n",
       "      <th>nabove</th>\n",
       "      <th>nbelow</th>\n",
       "      <th>ntrange</th>\n",
       "      <th>passes</th>\n",
       "      <th>review_length</th>\n",
       "      <th>setting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>[35, 60)</th>\n",
       "      <td>309850</td>\n",
       "      <td>A1</td>\n",
       "      <td>4733.592008</td>\n",
       "      <td>174930</td>\n",
       "      <td>0.5</td>\n",
       "      <td>30</td>\n",
       "      <td>[10, 25, 40, 55, 70, 85, 100]</td>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>LDA1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[35, 60)</th>\n",
       "      <td>309850</td>\n",
       "      <td>E1</td>\n",
       "      <td>4701.817000</td>\n",
       "      <td>174930</td>\n",
       "      <td>0.5</td>\n",
       "      <td>30</td>\n",
       "      <td>[10, 25, 40, 55, 70, 85, 100]</td>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>LDA1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[35, 60)</th>\n",
       "      <td>309850</td>\n",
       "      <td>E1</td>\n",
       "      <td>5805.913717</td>\n",
       "      <td>108447</td>\n",
       "      <td>0.5</td>\n",
       "      <td>20</td>\n",
       "      <td>[10, 25, 40, 55, 70, 85, 100]</td>\n",
       "      <td>50</td>\n",
       "      <td>150</td>\n",
       "      <td>LDA2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[35, 60)</th>\n",
       "      <td>309850</td>\n",
       "      <td>A1</td>\n",
       "      <td>5501.168062</td>\n",
       "      <td>108447</td>\n",
       "      <td>0.5</td>\n",
       "      <td>20</td>\n",
       "      <td>[10, 25, 40, 55, 70, 85, 100]</td>\n",
       "      <td>50</td>\n",
       "      <td>150</td>\n",
       "      <td>LDA2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          corpus_length data_configuration     duration  filtered_length  \\\n",
       "[35, 60)         309850                 A1  4733.592008           174930   \n",
       "[35, 60)         309850                 E1  4701.817000           174930   \n",
       "[35, 60)         309850                 E1  5805.913717           108447   \n",
       "[35, 60)         309850                 A1  5501.168062           108447   \n",
       "\n",
       "          nabove  nbelow                        ntrange  passes  \\\n",
       "[35, 60)     0.5      30  [10, 25, 40, 55, 70, 85, 100]      32   \n",
       "[35, 60)     0.5      30  [10, 25, 40, 55, 70, 85, 100]      32   \n",
       "[35, 60)     0.5      20  [10, 25, 40, 55, 70, 85, 100]      50   \n",
       "[35, 60)     0.5      20  [10, 25, 40, 55, 70, 85, 100]      50   \n",
       "\n",
       "          review_length setting  \n",
       "[35, 60)            100    LDA1  \n",
       "[35, 60)            100    LDA1  \n",
       "[35, 60)            150    LDA2  \n",
       "[35, 60)            150    LDA2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the experimental results if need be\n",
    "experimental_setup = pd.read_csv(os.getcwd()+'/documents/lda_experimental_register.csv', index_col =0)\n",
    "experimental_setup.loc['[35, 60)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
