{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided LDA Modeling\n",
    "\n",
    "Often an LDA models will return less than optimal results, this happens because the natural occurence of linguistic features may not be conducive to the identification of deeper meaning conveyed across an entire corpus. A guided LDA allows for the pre-determination of elements that may be at the center of clusters. Guided LDA uses a process known as [Gibbs sampling](https://www.pnas.org/content/101/suppl_1/5228.abstract) to identify the observations that most closely relate to a predetermined set of criteria. The implementation of guided LDA was first introduced in [this paper](https://www.aclweb.org/anthology/E12-1021) which was used to produce the python library used in this analysis. \n",
    "\n",
    "In the previous notebook, where we examined language models, we identified potential topics to set as seeds. In this notebook, we will use guided LDAs to try and improve on the results from our earlier LDA models. Similarly, we will use coherence to select the number of topics in each instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Cores: 3\n",
      "Available Cores: 3\n",
      "{'full clean': 'A1', 'with nots': 'C1'}\n",
      "A1\n",
      "ranges: ['[0, 35)']\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "import os\n",
    "import time\n",
    "import glob \n",
    "import numpy as np\n",
    "import modeling_tools as mt\n",
    "import bear_necessities as bn\n",
    "import lda_analysis as ld\n",
    "from importlib import reload\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "ld = reload(ld)\n",
    "mt = reload(mt)\n",
    "\n",
    "# import the ranges (we will need the range indices at the end)\n",
    "range_indices = bn.loosen(os.getcwd() + '/data/by_rating_range.pickle')\n",
    "ranges = list(np.sort(list(range_indices.keys())))\n",
    "ranges = [ranges[0]]\n",
    "\n",
    "# available configurations \n",
    "data_configs = {'full clean':'A1',\n",
    "                'with nots':'C1'}\n",
    "print(data_configs) \n",
    "\n",
    "dconf = input('Type in the configuration you want to use:')\n",
    "print(dconf)\n",
    "print('ranges:',ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set model parameters for guided LDA:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mconfig = {} \n",
    "mconfig['ntrange'] = [4] + list(range(8, 58, 7)) # list of topics (number of models) to try with each corpus \n",
    "mconfig['iters'] = 32 # number of passes through the corpus for each model \n",
    "mconfig['seed_confidence'] = 0.8\n",
    "mconfig['nbelow'] = 30\n",
    "mconfig['nabove'] = .5\n",
    "mconfig['name'] = 'G-LDA1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Retrieve seeds for guided LDA:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open seed words for topics \n",
    "files = glob.glob(os.getcwd() + '/data/subject_words/larger/*primary.txt')\n",
    "# throw them all into one list\n",
    "seed_topic_list = []\n",
    "for file in files: \n",
    "    with open(file, 'r') as f: \n",
    "        seed_topic_list.append(list(filter(None,f.read().split('\\n'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train guided LDA models:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Cores: 7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-f47ad128fa30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mld\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel_directory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_guidedlda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdconf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mranges\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed_topic_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Dropbox (Personal)\\Responsibilities\\Teachers_Profiles\\lda_analysis.py\u001b[0m in \u001b[0;36mrun_guidedlda\u001b[1;34m(dconf, mconfig, ranges, seed_topic_list)\u001b[0m\n\u001b[0;32m     65\u001b[0m                                                                                                                                \u001b[0mdconf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                                                                                                                                \u001b[0mmconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'nbelow'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m                                                                                                                                mconfig['nabove'])\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[1;31m# assign topic numbers to seed words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mseed_topics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox (Personal)\\Responsibilities\\Teachers_Profiles\\modeling_tools.py\u001b[0m in \u001b[0;36msetup_text_training_data\u001b[1;34m(rng, dconf, none_below, not_above)\u001b[0m\n\u001b[0;32m    332\u001b[0m     \u001b[0mstem_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecompress_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/data/cleaned_data/cleaned_stems_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mrng\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mdconf\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.pbz2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[0mlemma_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecompress_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/data/cleaned_data/cleaned_lemma_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mrng\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mdconf\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.pbz2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m     \u001b[0mphrase_freq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecompress_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/data/cleaned_data/cleaned_phrase_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mrng\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mdconf\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.pbz2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m     \u001b[1;31m# populate the dictionary elements and filter out low and high occurring words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[0mdictionary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mliteral_dictionary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword2id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset_dictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnone_below\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnot_above\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox (Personal)\\Responsibilities\\Teachers_Profiles\\modeling_tools.py\u001b[0m in \u001b[0;36mset_dictionary\u001b[1;34m(docs, nb, na)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m \u001b[1;31m# Setup dictionaries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mset_dictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m         \u001b[0mdictionary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\corpora\\dictionary.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, documents, prune_at)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdocuments\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_documents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune_at\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprune_at\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\corpora\\dictionary.py\u001b[0m in \u001b[0;36madd_documents\u001b[1;34m(self, documents, prune_at)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[1;31m# update Dictionary with the document\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_update\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# ignore the result, here we only care about updating token ids\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         logger.info(\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\corpora\\dictionary.py\u001b[0m in \u001b[0;36mdoc2bow\u001b[1;34m(self, document, allow_update, return_missing)\u001b[0m\n\u001b[0;32m    253\u001b[0m                     \u001b[1;31m# NOTE this assumes there are no gaps in the id sequence!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                     \u001b[0mtoken2id\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken2id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mtoken2id\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfreq\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtoken2id\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mallow_update\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\corpora\\dictionary.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    253\u001b[0m                     \u001b[1;31m# NOTE this assumes there are no gaps in the id sequence!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                     \u001b[0mtoken2id\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken2id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mtoken2id\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfreq\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtoken2id\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mallow_update\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ld = reload(ld)\n",
    "\n",
    "model_directory = ld.run_guidedlda(dconf, mconfig, [ranges[0]], seed_topic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_top_words = 10\n",
    "topic_word = model.topic_word_\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(list(id2word.values()))[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    print('Topic {}: {}'.format(i, ' '.join(topic_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# No multiprocessing for guided LDA\n",
    "model_directory = {} \n",
    "\n",
    "total_time = 0 \n",
    "# for each rating range (corpus) train a series of LDA models and test out coherence. \n",
    "for rng in ranges: \n",
    "    st = time.time()\n",
    "    # instantiate the dictionaries \n",
    "    docs, stem_map, lemma_map, phrase_freq, dictionary, literal_dictionary, id2word, word2id = mt.setup_text_training_data(rng, \n",
    "                                                                                                                           dconf, \n",
    "                                                                                                                           mconfig['nbelow'], \n",
    "                                                                                                                           mconfig['nabove'])\n",
    "    # assign topic numbers to seed words \n",
    "    seed_topics = {}\n",
    "    for t_id, st in enumerate(seed_topic_list):\n",
    "        for word in st:\n",
    "            try:\n",
    "                seed_topics[word2id[word]] = t_id\n",
    "            except: \n",
    "                print('Was not able to find %s in %s' % (str(word), str(rng)))    \n",
    "\n",
    "    # format the data as a document term matrix (required for guided LDA)\n",
    "    dtm = mt.bow2dtm(docs, dictionary)\n",
    "    dtm = dtm.astype(int) \n",
    "    iters = mconfig['iters'] \n",
    "    ntranges = mconfig['ntrange']\n",
    "    seed_confidence=mconfig['seed_confidence']\n",
    "\n",
    "    # train the guided lda models\n",
    "#     trained_models = mt.train_guidedLDAs(dtm) \n",
    "#                                    mconfig['iters'], \n",
    "#                                    mconfig['ntrange'], \n",
    "#                                    seed_topics, \n",
    "#                                    seed_confidence=mconfig['seed_confidence'])\n",
    "\n",
    "    # create an ordered dictionary to store the results from each model\n",
    "    trained_models = OrderedDict()\n",
    "\n",
    "    # we will train models for different numbers of topics and evaluate the coherence for each \n",
    "    for num_topics in ntrange: \n",
    "        \n",
    "        # train guided LDA model\n",
    "        model = guidedlda.GuidedLDA(n_topics=num_topics, \n",
    "                                    n_iter=iters, \n",
    "                                    random_state=7, \n",
    "                                    refresh=2)\n",
    "        model.fit(dtm, \n",
    "                  seed_topics=seed_topics, \n",
    "                  seed_confidence=seed_confidence)\n",
    "        \n",
    "        print(\"Training Guided LDA(k=%d)\" % num_topics)\n",
    "        \n",
    "        # add it to the dictionary of trained models \n",
    "        trained_models[num_topics] = lda     \n",
    "        \n",
    "    # print how long it took to train\n",
    "    print('Training all the models on the corpus for %s took %s' % (str(rng), str(time.time() - st)))\n",
    "    total_time += (time.time() - st) # start counting the total time it takes for training. \n",
    "    name = 'G-LDA_'+rng+'_'+dconf+'_'+mconfig['name'] # Each model will be named after its data configuration and corpus range\n",
    "    models_dir = os.getcwd() + '/models/'+name # Set the model directory name (will be created if does not exist)    \n",
    "    mt.save_models(trained_models, models_dir, name)\n",
    "\n",
    "    # save the models to a dictionary \n",
    "    model_directory[rng] = {}\n",
    "    model_directory[rng]['models'] = trained_models\n",
    "    model_directory[rng]['dictionary'] = dictionary \n",
    "    model_directory[rng]['docs'] = docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_topics = {}\n",
    "for t_id, st in enumerate(seed_topic_list):\n",
    "    for word in st:\n",
    "        try:\n",
    "            seed_topics[word2id[word]] = t_id\n",
    "        except: \n",
    "            print('Was not able to find %s in %s' % (str(word), str(rng)))    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rank models by coherence:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_models = ld.rank_by_coherence(model_directory, ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: ask_question bok learn properli idea want posibl prepar unfair far_behind\n",
      "Topic 1: time say efect god sit_around apeal use alow click confer\n",
      "Topic 2: part manipul world beter teach make lock blame downhil easi\n",
      "Topic 3: shel reali atitud quiz hate read_bok favorit say hand task\n",
      "Topic 4: teribl milion club told leson cla restrict easili especiali think\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
